{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgs/lI3x7G528Wi2Kj572F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrienpayong/codecommentgenerator/blob/main/Code_Comment_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code Comment Generator"
      ],
      "metadata": {
        "id": "kzPDuk7FEnej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7oj2BvEU7f",
        "outputId": "ddc8ef9b-2bf5-458c-da29-3631854ec48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this section is to have some code as input and let the model generate comments for that code. In this case we will use the Salesforce CodeT5 model, which is fine-tuned on Java code.\n",
        "As its name suggests, the T5 encoder-decoder paradigm is the foundation upon which CodeT5 [1] is built. Instead of treating the source code like any other natural language (NL) text, it applies a new identifier-aware pretraining objective that capitalizes on code semantics. This is in contrast with previous code generation models, which rely on traditional pretraining methods.\n",
        "The authors distributed two pretrained models: a basic model with 220 million data points and a smaller model with only 60 million data points. In addition to that, they distributed all of their fine-tuning checkpoints through their public GCP bucket. Additionally, the well-known huggingface library makes both of these pretrained models available for use.\n",
        "\n",
        "CodeT5 is a unified pretrained encoder-decoder transformer model. The CodeT5 approach makes use of a unified framework, which not only facilitates multitask learning but also supports code interpretation and generation activities in an effortless manner.\n",
        "The pretraining of CodeT5 is accomplished in a sequential manner using two separate goals. The model is optimized with an identifier-aware denoising objective during the first 100 epochs. This trains the model to distinguish between identifiers (such as variable names, function names, etc.) and specific programming language (PL) keywords (e.g., if, while, etc.). Then, optimization is performed for a total of 50 iterations utilizing a bimodal dual generation goal. As a final goal, we want to make sure that the code and the NL descriptions are more aligned with one another.\n",
        "Since this example needs to download models from a non-huggingface repository (as of writing this book, the model was not updated on huggingface), we will do this example in Google Colab instead of huggingface."
      ],
      "metadata": {
        "id": "Uo5CrjbmE8OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir comment_model\n",
        "%cd comment_model\n",
        "!wget -O config.json https://storage.googleapis.com/sfr-codet5-data-research/pretrained_models/codet5_base/config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GqPUw18Fayl",
        "outputId": "9bd8c568-a127-42f0-96d9-6f1c7475f266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/comment_model\n",
            "--2023-01-23 14:43:45--  https://storage.googleapis.com/sfr-codet5-data-research/pretrained_models/codet5_base/config.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1422 (1.4K) [application/json]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]   1.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-23 14:43:45 (25.4 MB/s) - ‘config.json’ saved [1422/1422]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10xH_TLNH5-e",
        "outputId": "f8c67dea-6615-4299-ce8d-05bf47185ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O pytorch_model.bin https://storage.googleapis.com/sfr-codet5-data-research/finetuned_models/summarize_java_codet5_base.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evwXJ1aTFh_w",
        "outputId": "27dec26f-4058-457b-f22c-05d80eef64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-23 14:44:12--  https://storage.googleapis.com/sfr-codet5-data-research/finetuned_models/summarize_java_codet5_base.bin\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891651384 (850M) [application/macbinary]\n",
            "Saving to: ‘pytorch_model.bin’\n",
            "\n",
            "pytorch_model.bin   100%[===================>] 850.34M   121MB/s    in 7.0s    \n",
            "\n",
            "2023-01-23 14:44:20 (121 MB/s) - ‘pytorch_model.bin’ saved [891651384/891651384]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
        "model_name_or_path = '/content/comment_model' # Path to the folder created earlier.\n",
        "codeT5_tkn = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
        "mdl = T5ForConditionalGeneration.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "gghoBcZhFs0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for comment generation from the source code file"
      ],
      "metadata": {
        "id": "bkT-HmaPF3k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" public static void main(String[] args) {\n",
        "\n",
        "    int num = 29;\n",
        "    boolean flag = false;\n",
        "    for (int i = 2; i <= num / 2; ++i) {\n",
        "    // condition for nonprime number\n",
        "        if (num % i == 0) {\n",
        "          flag = true;\n",
        "          break;\n",
        "         }\n",
        "    }\n",
        "if (!flag)\n",
        "    System.out.println(num + \" is a prime number.\");\n",
        "else\n",
        "  System.out.println(num + \" is not a prime number.\");\n",
        "} \"\"\""
      ],
      "metadata": {
        "id": "ZMROo_LKGAY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = codeT5_tkn(text, return_tensors=\"pt\").input_ids\n",
        "gen_ids = mdl.generate(input_ids, max_length=20)\n",
        "print(codeT5_tkn.decode(gen_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3JAVo9AHYwN",
        "outputId": "79d15d6f-5781-410b-d4f4-29c1855a5995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A test program that checks if the number is a prime number.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code that tries to generate comment for Google search code"
      ],
      "metadata": {
        "id": "RK68Zx9YI724"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "String google = \"http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q=\";\n",
        "    String search = \"stackoverflow\";\n",
        "    String charset = \"UTF-8\";\n",
        "    URL url = new URL(google + URLEncoder.encode(search, charset));\n",
        "    Reader reader = new InputStreamReader(url.openStream(), charset);\n",
        "    GoogleResults results = new Gson().fromJson(reader, GoogleResults.class);\n",
        "// Show title and URL of 1st result.\n",
        "System.out.println(results.getResponseData().getResults().get(0).getTitle());\n",
        "System.out.println(results.getResponseData().getResults().get(0).getUrl());\n",
        "\"\"\"\n",
        "input_ids = codeT5_tkn(text, return_tensors=\"pt\").input_ids\n",
        "gen_ids = mdl.generate(input_ids, max_length=50, temperature=0.2,num_beams=200,no_repeat_ngram_size=2,num_return_sequences=5)"
      ],
      "metadata": {
        "id": "-2XCNaTbJVc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(codeT5_tkn.decode(gen_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtbbySB6LaL3",
        "outputId": "096c7451-1a13-4b25-dc6e-ec368b71835e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www. googleapis. com / ajax. services. search. web?v = 1. 0 &q = 123 Show title and URL of 1st result.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last result might not look good, but this can be improved by tuning the specific parameters, which I leave to you to experiment with.\n",
        "Finally, these pretrained models can also be fine-tuned for specific programming languages like C, C++, etc"
      ],
      "metadata": {
        "id": "IwgudplILfs_"
      }
    }
  ]
}